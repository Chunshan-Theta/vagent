'use client';

import { useState, useEffect } from 'react';
import { FaChartBar, FaLightbulb, FaComments, FaHistory, FaArrowLeft, FaStar, FaVolumeUp, FaPlay } from 'react-icons/fa';
import confetti from 'canvas-confetti';
import { AnalysisResponse, AudioTimelineData, AudioInfo, ReportDatas } from '@/app/types/ai-report/common';
import { Radar, RadarChart, PolarGrid, PolarAngleAxis, PolarRadiusAxis, ResponsiveContainer, BarChart, Bar, XAxis, YAxis, CartesianGrid, Tooltip } from 'recharts';

interface Props {
  /**
   * åˆ†æçµæœæ•¸æ“šï¼Œå¯ä»¥æ˜¯ AnalysisResponse å°è±¡ã€AudioTimelineData å°è±¡æˆ– JSON å­—ç¬¦ä¸²
   */
  data: ReportDatas;
  onBack?: () => void;
  /**
   * ä¿å­˜çš„èŠå¤©ç´€éŒ„ ( å¯ä»¥æ˜¯ JSON å­—ç¬¦ä¸²æˆ– Array<Message> )
   */
  message?: any[] | string;
}

export default function AudioReportView({ data, onBack, message = '' }: Props) {
  const [localAnalysis, setLocalAnalysis] = useState<AnalysisResponse | null>(null);
  const [audioTimelineData, setAudioTimelineData] = useState<AudioTimelineData | null>(null);
  const [localMessage, setLocalMessage] = useState<string>('');
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState<string | null>(null);
  const [isAudioTimeline, setIsAudioTimeline] = useState(false);

  function getStoredChatMessages() : string {
    if (typeof message === 'string' && message.trim() !== '') {
      return message
    }
    if (Array.isArray(message)) {
      return JSON.stringify(message);
    }
    if (typeof window === 'undefined') return '[]';
    return localStorage.getItem('chatMessages') || '[]';
  }
  function getStoredAnalysis() {
    if (data && typeof data === 'object') {
      return JSON.stringify(data);
    }
    if (typeof window === 'undefined') return '{}';
    return localStorage.getItem('analyzeChatHistoryByRubric');
  }

  // Helper function to parse audioInfo
  const parseAudioInfo = (audioInfoString: string): AudioInfo | null => {
    try {
      return JSON.parse(audioInfoString);
    } catch {
      return null;
    }
  };

  // Helper function to get emotion color
  const getEmotionColor = (emotion: string) => {
    const emotionColors: Record<string, string> = {
      'Positive': 'text-green-400',
      'Negative': 'text-red-400',
      'Neutral': 'text-gray-400',
      'Questioning': 'text-blue-400',
      'Reassuring': 'text-yellow-400',
      'Affirmative': 'text-green-300',
      'Amused': 'text-purple-400',
      'æœªæ¨™è¨˜': 'text-gray-500',
      'ç©©å®šä¸­ç«‹': 'text-gray-300',
      'Empathetic': 'text-green-400',
      'Appreciative': 'text-green-300',
      'Hesitant': 'text-orange-400',
      'Assertive': 'text-blue-400',
      'Concerned': 'text-yellow-400',
      'Frustrated': 'text-red-400',
      'Authoritative': 'text-purple-400',
      'Helpful': 'text-green-300',
      'Aggressive': 'text-red-500',
      // New emotion tags
      'Lighthearted': 'text-pink-400',
      'Friendly': 'text-green-300',
      'Understanding': 'text-blue-300',
      'Acknowledging': 'text-teal-400',
      'Cooperative': 'text-green-400',
      'Suggestive': 'text-blue-400',
      'Accommodating': 'text-green-300',
      'Explanatory': 'text-blue-300',
      'Practical': 'text-gray-300',
      'Encouraging': 'text-green-400',
      'Considerate': 'text-green-300',
      'Responsible': 'text-blue-400',
      'Informative': 'text-cyan-400'
    };
    return emotionColors[emotion] || 'text-gray-400';
  };

  // Helper function to analyze audio timeline data
  const analyzeAudioTimeline = (timelineData: AudioTimelineData): AnalysisResponse => {
    const timeline = timelineData.timeline;
    const totalEmotions: Record<string, number> = {};
    const allProblems: string[] = [];
    const allAnalysis: string[] = [];
    let conversationLength = 0;

    // Define emotion polarity
    const positiveEmotions = [
      'Empathetic', 'Appreciative', 'Assertive', 'Helpful', 'Authoritative',
      'Lighthearted', 'Friendly', 'Understanding', 'Acknowledging', 'Cooperative', 'Accommodating', 
      'Encouraging', 'Considerate', 'Responsible', 'Informative', 'Reassuring', 'Positive'
    ];
    const negativeEmotions = ['Hesitant', 'Concerned', 'Frustrated', 'Aggressive','Anxious',"Desperate"];
    const neutralEmotions = ['Suggestive', 'Explanatory', 'Practical', 'Neutral', 'Questioning'];
    
    // keyEmotions ç‚ºç¸½å’Œæ­£è² ç›¸çš„å­—è©
    const keyEmotions = [...positiveEmotions, ...negativeEmotions, ...neutralEmotions];

    // Track processed audioInfo to avoid duplicates
    const processedAudioInfo = new Set<string>();
    
    timeline.forEach(conversation => {
      // Collect problems and analysis
      allProblems.push(...conversation.keyPoint.problems);
      allAnalysis.push(...conversation.analysis);

      // Parse audio info for emotion analysis (avoid duplicates)
      if (conversation.userAudio?.audioInfo && !processedAudioInfo.has(conversation.userAudio.audioInfo)) {
        processedAudioInfo.add(conversation.userAudio.audioInfo);
        const audioInfo = parseAudioInfo(conversation.userAudio.audioInfo);
        if (audioInfo) {
          conversationLength += audioInfo.emotions.length;
          audioInfo.emotions.forEach(emotion => {
            // Split emotions by comma and space
            const emotions = emotion.emotion.split(/[,\s]+/).filter(e => e.trim() !== '');
            emotions.forEach(singleEmotion => {
              const trimmedEmotion = singleEmotion.trim();
              if (keyEmotions.includes(trimmedEmotion)) {
                totalEmotions[trimmedEmotion] = (totalEmotions[trimmedEmotion] || 0) + 1;
              } else {
                console.log(`trimmedEmotion: ${trimmedEmotion}`);
                // Group others together but don't affect calculation
                totalEmotions['Others'] = (totalEmotions['Others'] || 0) + 1;
              }
            });
          });
        }
      }
    });

    // Calculate emotion counts and polarity scores
    const keyEmotionCount = keyEmotions.reduce((sum, emotion) => sum + (totalEmotions[emotion] || 0), 0);
    const positiveEmotionCount = positiveEmotions.reduce((sum, emotion) => sum + (totalEmotions[emotion] || 0), 0);
    const negativeEmotionCount = negativeEmotions.reduce((sum, emotion) => sum + (totalEmotions[emotion] || 0), 0);
    const totalEmotionCount = Object.values(totalEmotions).reduce((sum, count) => sum + count, 0);
    
    // Calculate polarity-weighted score (positive emotions add more value, negative emotions reduce value)
    const polarityScore = (positiveEmotionCount * 15) - (negativeEmotionCount * 5) + (keyEmotionCount * 5);
    const overallScore = Math.min(100, Math.max(0, polarityScore));

    return {
      overallScore,
      feedback: `åŸºæ–¼å°è©±ä¸­çš„æƒ…ç·’åˆ†æå’Œäº¤æµæ¨¡å¼ï¼Œæ‚¨çš„æ•´é«”è¡¨ç¾ç‚º ${overallScore.toFixed(0)} åˆ†ã€‚`,
      summary: `æ­¤æ¬¡å°è©±åŒ…å« ${timeline.length} å€‹æ™‚é–“æ®µï¼Œæ¶µè“‹äº† ${conversationLength} å€‹æƒ…ç·’æ¨™è¨˜çš„å¥å­ã€‚é—œéµæƒ…ç·’æ•¸é‡ï¼š${keyEmotionCount} æ¬¡ï¼ˆæ­£é¢æƒ…ç·’ï¼š${positiveEmotionCount} æ¬¡ï¼Œè² é¢æƒ…ç·’ï¼š${negativeEmotionCount} æ¬¡ï¼‰ï¼Œç¸½æƒ…ç·’æ¨™è¨˜æ•¸é‡ï¼š${totalEmotionCount} æ¬¡ã€‚æƒ…ç·’åˆ†å¸ƒï¼š${Object.entries(totalEmotions).map(([emotion, count]) => `${emotion}(${count}æ¬¡)`).join('ã€')}ã€‚`,
      overallImprovementTips: allAnalysis.slice(0, 5),
      scores: [
        {
          criterion: 'èªé€ŸæŒæ§åŠ›',
          score: (() => {
            // åŸºæ–¼å°è©±æ™‚é–“é•·åº¦å’Œæƒ…ç·’è®ŠåŒ–é »ç‡è¨ˆç®—
            const timeBasedScore = Math.min(40, 30 + Math.log(conversationLength + 1) * 8);
            const emotionStability = keyEmotionCount > 0 ? (positiveEmotionCount / keyEmotionCount) * 30 : 20;
            return Math.min(98, Math.max(25, timeBasedScore + emotionStability));
          })(),
          explanation: `åŸºæ–¼ ${conversationLength} å¥å°è©±é•·åº¦å’Œæƒ…ç·’ç©©å®šåº¦åˆ†æèªé€Ÿæ§åˆ¶`,
          examples: timeline.flatMap(conv => conv.userSay ? [conv.userSay.substring(0, 50) + '...'] : []).slice(0, 2),
          improvementTips: ['æ³¨æ„èªªè©±é€Ÿåº¦ï¼Œé¿å…éå¿«æˆ–éæ…¢', 'é…åˆè½çœ¾ç†è§£ç¯€å¥èª¿æ•´èªé€Ÿ']
        },
        {
          criterion: 'éŸ³é‡ç©©å®šåŠ›',
          score: (() => {
            // åŸºæ–¼è² é¢æƒ…ç·’æ³¢å‹•å’Œå°è©±ä¸€è‡´æ€§
            const stabilityPenalty = negativeEmotionCount * 3;
            const consistencyBonus = timeline.length > 3 ? 15 : timeline.length * 5;
            return Math.min(98, Math.max(25, 70 - stabilityPenalty + consistencyBonus));
          })(),
          explanation: `åŸºæ–¼ ${timeline.length} å€‹æ™‚é–“æ®µçš„å°è©±ä¸€è‡´æ€§å’Œæƒ…ç·’æ³¢å‹•åˆ†æ`,
          examples: timeline.flatMap(conv => conv.userSay ? [conv.userSay.substring(0, 50) + '...'] : []).slice(0, 2),
          improvementTips: ['ä¿æŒéŸ³é‡ç©©å®šï¼Œé¿å…å¿½å¤§å¿½å°', 'æ ¹æ“šç’°å¢ƒèª¿æ•´é©ç•¶éŸ³é‡']
        },
        {
          criterion: 'èªéŸ³æ¸…æ™°åŠ›',
          score: (() => {
            // åŸºæ–¼å¥å­å¹³å‡é•·åº¦å’Œå°ˆæ¥­è©å½™ä½¿ç”¨
            const avgSentenceLength = timeline.reduce((sum, conv) => sum + (conv.userSay?.length || 0), 0) / timeline.length;
            const clarityScore = avgSentenceLength > 50 ? 75 - (avgSentenceLength - 50) * 0.3 : 75;
            const positiveAdjustment = Math.min(15, positiveEmotionCount * 1.2);
            return Math.min(98, Math.max(25, clarityScore + positiveAdjustment));
          })(),
          explanation: `åŸºæ–¼å¹³å‡å¥é•·å’Œè¡¨é”æ¸…æ™°åº¦è©•ä¼°`,
          examples: timeline.flatMap(conv => conv.userSay ? [conv.userSay.substring(0, 50) + '...'] : []).slice(0, 2),
          improvementTips: ['æ³¨æ„ç™¼éŸ³æ¸…æ™°ï¼Œé¿å…å«ç³Šä¸æ¸…', 'é‡è¦è©å½™è¦ç‰¹åˆ¥æ¸…æ¥šè¡¨é”']
        },
        {
          criterion: 'åœé “é‹ç”¨åŠ›',
          score: (() => {
            // åŸºæ–¼å•è™Ÿå’Œæ¨™é»ç¬¦è™Ÿçš„ä½¿ç”¨é »ç‡
            const questionCount = timeline.reduce((count, conv) => 
              count + (conv.userSay?.split('?').length - 1 || 0), 0);
            const pauseSkill = questionCount > 0 ? 60 + questionCount * 8 : 45;
            const emotionBalance = (positiveEmotionCount - negativeEmotionCount) * 2;
            return Math.min(98, Math.max(25, pauseSkill + emotionBalance));
          })(),
          explanation: `åŸºæ–¼æå•æŠ€å·§å’Œèªå¥çµæ§‹åˆ†æåœé “é‹ç”¨`,
          examples: timeline.flatMap(conv => conv.userSay ? [conv.userSay.substring(0, 50) + '...'] : []).slice(0, 2),
          improvementTips: ['å–„ç”¨åœé “å¹«åŠ©ç†è§£', 'é¿å…ä¸å¿…è¦çš„åœé “é€ æˆå¡é “æ„Ÿ']
        },
        {
          criterion: 'å£èªæµæš¢åŠ›',
          score: (() => {
            // ç›´æ¥åŸºæ–¼å•é¡Œæ•¸é‡è¨ˆç®—ï¼Œå•é¡Œè¶Šå¤šæ‰£åˆ†è¶Šå¤š
            const problemPenalty = allProblems.length * 2;
            const baseScore = 98;
            const emotionBonus = Math.min(10, (positiveEmotionCount*1.5 - negativeEmotionCount*0.5));
            return Math.min(98, Math.max(25, baseScore - problemPenalty*0.5 + emotionBonus));
          })(),
          explanation: `ç™¼ç¾ ${allProblems.length} å€‹æµæš¢æ€§å•é¡Œï¼Œå½±éŸ¿æµæš¢åº¦è©•åˆ†`,
          examples: allProblems.slice(0, 2),
          improvementTips: ['ä¿æŒè‡ªç„¶æµæš¢çš„è¡¨é”', 'æ¸›å°‘ä¸å¿…è¦çš„é‡è¤‡å’Œåœé “']
        },
        {
          criterion: 'èªªè©±ç°¡æ½”åŠ›',
          score: (() => {
            // åŸºæ–¼å¹³å‡å›æ‡‰é•·åº¦å’Œé‡è¤‡è©å½™
            const totalLength = timeline.reduce((sum, conv) => sum + (conv.userSay?.length || 0), 0);
            const avgLength = totalLength / timeline.length;
            const conciseScore = avgLength < 80 ? 80 : Math.max(40, 120 - avgLength * 0.5);
            const problemAdjustment = allProblems.length * -0.5;
            return Math.min(98, Math.max(65, conciseScore + problemAdjustment));
          })(),
          explanation: `åŸºæ–¼å¹³å‡å›æ‡‰é•·åº¦å’Œè¡¨é”ç²¾æº–åº¦è©•ä¼°`,
          examples: timeline.flatMap(conv => conv.userSay && conv.userSay.length > 100 ? [conv.userSay.substring(0, 60) + '...'] : []).slice(0, 2),
          improvementTips: ['é¿å…é‡è¤‡ç”¨è©', 'è¡¨é”è¦ç²¾æº–ä¿è½']
        },
        {
          criterion: 'é‡é»å‚³é”åŠ›',
          score: (() => {
            // åŸºæ–¼é—œéµè©ä½¿ç”¨å’Œå¼·èª¿èªå¥
            const emphasisWords = timeline.reduce((count, conv) => {
              const emphasisPatterns = /[!ï¼]{1,3}|[ã€‚]{2,}|[é‡è¦|é—œéµ|å¿…é ˆ|ä¸€å®š]/g;
              return count + (conv.userSay?.match(emphasisPatterns)?.length || 0);
            }, 0);
            const emphasisScore = 50 + emphasisWords * 5;
            const emotionBonus = positiveEmotionCount * 1.5;
            return Math.min(98, Math.max(25, emphasisScore + emotionBonus));
          })(),
          explanation: `åŸºæ–¼é‡é»å¼·èª¿æŠ€å·§å’Œèªæ°£é‹ç”¨è©•ä¼°`,
          examples: timeline.flatMap(conv => conv.userSay ? [conv.userSay.substring(0, 50) + '...'] : []).slice(0, 2),
          improvementTips: ['åœ¨é—œéµè©å¥ä¸ŠåŠ å¼·èªæ°£', 'æå‡èªªæœåŠ›èˆ‡å¼•å°åŠ›']
        },
        {
          criterion: 'èªèª¿è¡¨é”åŠ›',
          score: (() => {
            // åŸºæ–¼æƒ…ç·’å¤šæ¨£æ€§è¨ˆç®—èªèª¿è±å¯Œåº¦
            const emotionVariety = Object.keys(totalEmotions).filter(emotion => emotion !== 'Others').length;
            const varietyScore = Math.min(40, emotionVariety * 4);
            const intensityScore = keyEmotionCount > 0 ? Math.min(35, keyEmotionCount * 2.5) : 0;
            const baseScore = 25;
            return Math.min(98, Math.max(25, baseScore + varietyScore + intensityScore));
          })(),
          explanation: `åŸºæ–¼ ${Object.keys(totalEmotions).filter(e => e !== 'Others').length} ç¨®æƒ…ç·’é¡å‹çš„èªèª¿è±å¯Œåº¦è©•ä¼°`,
          examples: timeline
            .filter(conv => conv.userAudio?.audioInfo)
            .map(conv => parseAudioInfo(conv.userAudio!.audioInfo!))
            .filter(info => info)
            .flatMap(info => info!.emotions.flatMap(e => {
              const emotions = e.emotion.split(/[,\s]+/).filter(em => em.trim() !== '');
              return emotions.filter(emotion => keyEmotions.includes(emotion.trim())).map(emotion => `${emotion.trim()}: "${e.sentence.substring(0, 40)}..."`);
            }))
            .slice(0, 2),
          improvementTips: ['å¢åŠ èªèª¿çš„æŠ‘æšé “æŒ«', 'é¿å…å¹³æ·¡ç„¡æƒ…ç·’çš„è¡¨é”']
        },
        {
          criterion: 'è²éŸ³æ´»åŠ›åº¦',
          score: (() => {
            // åŸºæ–¼ç©æ¥µæƒ…ç·’å¯†åº¦è¨ˆç®—æ´»åŠ›
            const energyEmotions = ['Helpful', 'Lighthearted', 'Encouraging', 'Positive'];
            const energyCount = energyEmotions.reduce((sum, emotion) => sum + (totalEmotions[emotion] || 0), 0);
            const densityScore = conversationLength > 0 ? (energyCount / conversationLength) * 100 : 30;
            const baseEnergy = 40;
            return Math.min(98, Math.max(25, baseEnergy + densityScore));
          })(),
          explanation: `åŸºæ–¼ç©æ¥µæƒ…ç·’å¯†åº¦å’Œè¡¨é”æ´»åŠ›åº¦è©•ä¼°`,
          examples: timeline.flatMap(conv => conv.userSay ? [conv.userSay.substring(0, 50) + '...'] : []).slice(0, 2),
          improvementTips: ['ä¿æŒè²éŸ³çš„æ´»åŠ›èˆ‡ç²¾ç¥', 'è®“è²éŸ³æ›´æœ‰æ„ŸæŸ“åŠ›']
        },
        {
          criterion: 'è¦ªå’Œèªæ°£åŠ›',
          score: (() => {
            // åŸºæ–¼å‹å–„æƒ…ç·’æ¯”ä¾‹å’Œç¦®è²Œç”¨èª
            const friendlyEmotions = ['Empathetic', 'Friendly', 'Understanding', 'Cooperative', 'Considerate'];
            const friendlyCount = friendlyEmotions.reduce((sum, emotion) => sum + (totalEmotions[emotion] || 0), 0);
            const friendlyRatio = keyEmotionCount > 0 ? friendlyCount / keyEmotionCount : 0;
            const affinityScore = 45 + friendlyRatio * 40;
            const courtesyBonus = timeline.reduce((count, conv) => {
              const courtesyWords = /[è¬è¬|æ„Ÿè¬|è«‹|éº»ç…©|ä¸å¥½æ„æ€|å°ä¸èµ·]/g;
              return count + (conv.userSay?.match(courtesyWords)?.length || 0);
            }, 0) * 3;
            return Math.min(98, Math.max(25, affinityScore + courtesyBonus));
          })(),
          explanation: `åŸºæ–¼å‹å–„æƒ…ç·’æ¯”ä¾‹å’Œç¦®è²Œç”¨èªä½¿ç”¨è©•ä¼°`,
          examples: timeline.flatMap(conv => conv.userSay ? [conv.userSay.substring(0, 50) + '...'] : []).slice(0, 2),
          improvementTips: ['ä½¿ç”¨æº«æš–å‹å–„çš„èªæ°£', 'è®“å°æ–¹æ„Ÿå—åˆ°è¢«å°Šé‡']
        },
        {
          criterion: 'ç©©å®šæ‡‰å°åŠ›',
          score: (() => {
            // åŸºæ–¼æƒ…ç·’æ–¹å·®å’Œå•é¡Œè™•ç†èƒ½åŠ›
            const emotionSpread = keyEmotionCount > 0 ? 
              Math.sqrt(Object.values(totalEmotions).reduce((sum, count) => sum + Math.pow(count - (keyEmotionCount / Object.keys(totalEmotions).length), 2), 0) / Object.keys(totalEmotions).length) : 0;
            const stabilityScore = 80 - emotionSpread * 2;
            const problemHandling = Math.max(0, 20 - allProblems.length * 2);
            return Math.min(98, Math.max(25, stabilityScore + problemHandling));
          })(),
          explanation: `åŸºæ–¼æƒ…ç·’åˆ†å¸ƒç©©å®šæ€§å’Œå•é¡Œæ‡‰å°èƒ½åŠ›è©•ä¼°`,
          examples: allProblems.slice(0, 2),
          improvementTips: ['ä¿æŒå†·éœèˆ‡ä¸€è‡´æ€§', 'ä¸å› å°æ–¹æ…‹åº¦è€Œæƒ…ç·’æ³¢å‹•']
        },
        {
          criterion: 'æ­£å‘æƒ…ç·’å‚³é”åŠ›',
          score: (() => {
            // ç´”ç²¹åŸºæ–¼æ­£é¢æƒ…ç·’ä½”æ¯”
            const positiveRatio = totalEmotionCount > 0 ? positiveEmotionCount / totalEmotionCount : 0;
            const transmissionScore = 30 + positiveRatio * 55;
            const intensityBonus = Math.min(15, positiveEmotionCount * 1.5);
            return Math.min(98, Math.max(25, transmissionScore + intensityBonus));
          })(),
          explanation: `æ­£é¢æƒ…ç·’ä½”æ¯” ${totalEmotionCount > 0 ? ((positiveEmotionCount / totalEmotionCount) * 100).toFixed(1) : 0}%ï¼Œæ­£å‘å‚³é”åŠ›è©•ä¼°`,
          examples: timeline
            .filter(conv => conv.userAudio?.audioInfo)
            .map(conv => parseAudioInfo(conv.userAudio!.audioInfo!))
            .filter(info => info)
            .flatMap(info => info!.emotions.filter(e => {
              const emotions = e.emotion.split(/[,\s]+/).filter(em => em.trim() !== '');
              return emotions.some(emotion => [
                'Empathetic', 'Appreciative', 'Helpful', 'Lighthearted', 'Friendly', 'Understanding', 
                'Acknowledging', 'Cooperative', 'Accommodating', 'Encouraging', 'Considerate', 'Responsible', 'Informative',
                'Reassuring', 'Positive'
              ].includes(emotion.trim()));
            }).map(e => e.sentence.substring(0, 40) + '...'))
            .slice(0, 2),
          improvementTips: ['é€éè²éŸ³å‚³éè‡ªä¿¡èˆ‡ç†±æƒ…', 'ç‡Ÿé€ ç©æ¥µæ­£å‘çš„æ°›åœ']
        },
        {
          criterion: 'è²éŸ³æ€§æ ¼åˆ†æ',
          score: (() => {
            // åŸºæ–¼ä¸»å°æƒ…ç·’é¡å‹å’Œä¸€è‡´æ€§
            const dominantEmotion = Object.entries(totalEmotions)
              .filter(([emotion]) => emotion !== 'Others')
              .reduce((a, b) => a[1] > b[1] ? a : b, ['', 0]);
            const consistencyScore = dominantEmotion[1] > 0 ? 
              50 + Math.min(30, (dominantEmotion[1] / totalEmotionCount) * 60) : 40;
            const diversityPenalty = Object.keys(totalEmotions).length > 8 ? 10 : 0;
            const personalityScore = consistencyScore - diversityPenalty;
            return Math.min(98, Math.max(25, personalityScore + (positiveEmotionCount - negativeEmotionCount)));
          })(),
          explanation: `åŸºæ–¼ä¸»å°æƒ…ç·’ä¸€è‡´æ€§å’Œå€‹æ€§ç©©å®šåº¦è©•ä¼°`,
          examples: timeline.flatMap(conv => conv.userSay ? [conv.userSay.substring(0, 50) + '...'] : []).slice(0, 2),
          improvementTips: ['å»ºç«‹ä¸€è‡´çš„æºé€šé¢¨æ ¼', 'å±•ç¾å¯ä¿¡ä»»çš„è²éŸ³å€‹æ€§']
        }
      ],
      language: 'zh'
    };
  };

  // Check for history parameter in URL and retrieve analysis from localStorage
  useEffect(() => {
    if (typeof window === 'undefined') return;

    // Get the analysis result and chat history from localStorage
    const storedAnalysis = getStoredAnalysis();
    const storedChatMessages = getStoredChatMessages();

    const getMsgContent = (msg: any) => {
      if (typeof msg === 'string') return msg;
      if (msg && typeof msg === 'object') {
        return (msg.content ?? msg.title) || '';
      }
      return '';
    }

    const storedChatHistory = storedChatMessages ?
      JSON.parse(storedChatMessages)
        .filter((msg: any) => msg.role !== 'system')
        .map((msg: any) => `${msg.role}: ${getMsgContent(msg)}`)
        .join('\n\n') : '';

    if (storedAnalysis && storedChatHistory) {
      try {
        const parsedData = JSON.parse(storedAnalysis);

        // Check if it's audio timeline data
        if (parsedData.timeline && Array.isArray(parsedData.timeline)) {
          setAudioTimelineData(parsedData);
          setIsAudioTimeline(true);
          const analysisResult = analyzeAudioTimeline(parsedData);
          setLocalAnalysis(analysisResult);
        } else {
          // Original AnalysisResponse format
          if (Array.isArray(parsedData.scores)) {
            for (const scoreItem of parsedData.scores) {
              if (Array.isArray(scoreItem.examples)) {
                scoreItem.examples = scoreItem.examples.map((example: string) => example.trim());
              }
            }
          }
          setLocalAnalysis(parsedData);
          setIsAudioTimeline(false);
        }

        setLocalMessage(storedChatHistory);
        setLoading(false);

        // Trigger confetti if score is high
        const finalScore = isAudioTimeline ? analyzeAudioTimeline(parsedData).overallScore : parsedData.overallScore;
        if (finalScore >= 80) {
          setTimeout(() => {
            confetti({
              particleCount: 100,
              spread: 70,
              origin: { y: 0.6 }
            });
          }, 1000);
        }
      } catch (err) {
        console.error('Error parsing stored analysis:', err);
        setError('Error loading analysis results');
        setLoading(false);
      }
    } else {
      setError('No analysis results or chat history found');
      setLoading(false);
    }
  }, []);

  // Function to get overall score color
  const getOverallScoreColor = (score: number) => {
    if (score >= 80) return 'text-[#FFE066]';
    if (score >= 60) return 'text-[#00A3E0]';
    if (score >= 40) return 'text-[#FFBD1F]';
    return 'text-red-400';
  };

  // Function to get emoji based on score
  const getScoreEmoji = (score: number) => {
    if (score >= 80) return 'ğŸŒŸ';
    if (score >= 60) return 'ğŸ‘';
    if (score >= 40) return 'ğŸ˜';
    return 'ğŸ˜•';
  };

  // Function to get progress bar color based on score
  const getProgressBarColor = (score: number) => {
    if (score >= 80) return 'bg-[#FFE066]';
    if (score >= 60) return 'bg-[#00A3E0]';
    if (score >= 40) return 'bg-[#FFBD1F]';
    return 'bg-red-400';
  };

  // Function to get localized UI text based on language
  const getLocalizedText = (key: string) => {
    const language = localAnalysis?.language || 'en';

    const localizedTexts: Record<string, Record<string, string>> = {
      en: {
        title: 'Conversation Analysis Report',
        backToDemo: 'Back',
        analyzing: 'Analyzing conversation...',
        error: 'Error',
        analysisResults: 'Analysis Results',
        conversationSummary: 'Conversation Summary',
        overallImprovementTips: 'Overall Improvement Tips',
        detailedScores: 'Detailed Scores',
        examples: 'Examples from the conversation:',
        improvementTips: 'Improvement Tips:',
        conversationHistory: 'Conversation History',
      },
      zh: {
        title: 'å°è©±åˆ†æå ±å‘Š',
        backToDemo: 'è¿”å›',
        analyzing: 'æ­£åœ¨åˆ†æ...',
        error: 'éŒ¯èª¤',
        analysisResults: 'åˆ†æçµæœ',
        conversationSummary: 'å°è©±æ‘˜è¦',
        overallImprovementTips: 'æ•´é«”æ”¹é€²å»ºè­°',
        detailedScores: 'è©•åˆ†ç´°ç¯€',
        examples: 'å°è©±ä¸­æåˆ°:',
        improvementTips: 'æ”¹é€²å»ºè­°:',
        conversationHistory: 'å°è©±ç´€éŒ„',
      }
    };

    return localizedTexts[language]?.[key] || localizedTexts['en'][key];
  };

  // Render audio timeline section
  const renderAudioTimeline = () => {
    if (!audioTimelineData) return null;

    return (
      <div className="mt-8 space-y-6">
        <h3 className="text-xl font-semibold text-white mb-3 flex items-center">
          <FaVolumeUp className="mr-2 text-[#FFE066]" />
          å°è©±æ™‚é–“è»¸åˆ†æ
        </h3>
        {audioTimelineData.timeline.map((conversation, index) => (
          <div key={index} className="p-5 rounded-[20px] border border-[#2D5A67] bg-[#173944] shadow-[0_4px_20px_rgba(0,160,255,0.15)]">
            <div className="flex justify-between items-center mb-3">
              <h4 className="font-bold text-lg text-white">{conversation.title}</h4>
            </div>
            
            {/* AI and User conversation */}
            <div className="space-y-3">
              <div className="bg-[#2D5A67] bg-opacity-50 p-3 rounded-[16px]">
                <div className="flex items-center mb-2">
                  <span className="text-[#FFE066] font-semibold mr-2">{conversation.aiRole}:</span>
                  {/* {conversation.aiAudio && (
                    <FaPlay className="text-[#FFE066] cursor-pointer hover:text-white transition-colors" 
                          onClick={() => window.open(conversation.aiAudio!.url, '_blank')} />
                  )} */}
                </div>
                <p className="text-white text-sm">{conversation.aiSay}</p>
              </div>
              
              <div className="bg-[#2D5A67] bg-opacity-50 p-3 rounded-[16px]">
                <div className="flex items-center mb-2">
                  <span className="text-[#00A3E0] font-semibold mr-2">{conversation.userRole}:</span>
                  {/* {conversation.userAudio && (
                    <FaPlay className="text-[#00A3E0] cursor-pointer hover:text-white transition-colors ml-2" 
                          onClick={() => window.open(conversation.userAudio!.url, '_blank')} />
                  )} */}
                </div>
                <p className="text-white text-sm mb-2">{conversation.userSay}</p>
                
                {/* Emotion analysis from audioInfo - show only relevant emotions for this time segment */}
                {conversation.userAudio?.audioInfo && (() => {
                  const audioInfo = parseAudioInfo(conversation.userAudio.audioInfo);
                  if (!audioInfo) return null;
                  
                  const currentEmotion = audioInfo.emotions[index];
                  const emotionTags = currentEmotion ? 
                    currentEmotion.emotion.split(/[,\s]+/).filter(e => e.trim() !== '') : 
                    ['ç©©å®šä¸­ç«‹'];
                  
                  return (
                    <div className="mt-2 space-y-1">
                      <h5 className="text-xs font-semibold text-[#FFE066]">æƒ…ç·’åˆ†æ:</h5>
                      <div className="flex flex-wrap gap-1">
                        {emotionTags.map((singleEmotion, idx) => (
                          <span key={idx} className={`text-xs px-2 py-1 rounded ${getEmotionColor(singleEmotion.trim())} bg-[#2D5A67]`}>
                            {singleEmotion.trim()}
                          </span>
                        ))}
                      </div>
                    </div>
                  );
                })()}
              </div>
            </div>

            {/* Analysis and key points */}
            {conversation.analysis.length > 0 && (
              <div className="mt-3 bg-[#2D5A67] bg-opacity-30 p-3 rounded-[16px]">
                <h5 className="font-semibold text-white mb-2 flex items-center">
                  <FaLightbulb className="mr-2 text-[#FFE066]" />
                  æ”¹é€²å»ºè­°
                </h5>
                <ul className="list-disc pl-5 space-y-1">
                  {conversation.analysis.slice(0, 3).map((tip, idx) => (
                    <li key={idx} className="text-white text-sm">{tip}</li>
                  ))}
                </ul>
              </div>
            )}
          </div>
        ))}
      </div>
    );
  };

  return (
    <div className="analysis-page container mx-auto p-4 max-w-4xl bg-[#0F2D38] rounded-[20px] shadow-[0_4px_20px_rgba(0,160,255,0.15)]">
      {loading ? (
        <div className="text-white text-center py-8">Loading...</div>
      ) : error ? (
        <div className="text-red-400 text-center py-8">{error}</div>
      ) : (
        <>
          <div className="flex justify-between items-center mb-6 bg-[#194A54] p-4 rounded-[12px] shadow-[inset_0_0_6px_rgba(0,255,255,0.15)]">
            <h1 className="text-3xl font-bold text-white border-b pb-2 flex items-center">
              <FaChartBar className="mr-2 text-[#FFE066]" />
              {isAudioTimeline ? 'éŸ³é »å°è©±åˆ†æå ±å‘Š' : getLocalizedText('title')}
            </h1>
            {onBack && (
              <button
                onClick={onBack}
                className="bg-[#00A3E0] text-white px-4 py-2 rounded-full hover:bg-[#00A3E0]/90 transition-colors duration-200 shadow-[0_2px_4px_rgba(0,160,255,0.3)] flex items-center"
              >
                <FaArrowLeft className="mr-2" />
                {getLocalizedText('backToDemo')}
              </button>
            )}
          </div>

          <div className="mt-8 space-y-6">

            {/* Summary Section */}
            <div className="p-6 bg-[#173944] rounded-[20px] border border-[#2D5A67] shadow-[0_4px_20px_rgba(0,160,255,0.15)]">
              <h2 className="text-2xl font-bold text-white mb-4 flex items-center">
                <FaComments className="mr-2 text-[#FFE066]" />
                {getLocalizedText('conversationSummary')}
              </h2>
              <p className="text-white text-lg mb-6">{localAnalysis?.summary}</p>
              
              {/* Emotion Distribution Bar Chart */}
              {isAudioTimeline && audioTimelineData && (
                <div className="mt-4">
                  <h3 className="text-lg font-semibold text-white mb-3">æƒ…ç·’åˆ†å¸ƒåœ–</h3>
                  <div className="h-64">
                    <ResponsiveContainer width="100%" height="100%">
                      <BarChart
                        data={(() => {
                          // Calculate emotions for chart - avoid duplicate audioInfo, separate key emotions from others
                          const chartEmotions: Record<string, number> = {};
                          const processedAudioInfo = new Set<string>();
                          
                          // Use same emotion definitions
                          const positiveEmotions = [
                            'Empathetic', 'Appreciative', 'Assertive', 'Helpful', 'Authoritative',
                            'Lighthearted', 'Friendly', 'Understanding', 'Acknowledging', 'Cooperative', 'Accommodating', 
                            'Encouraging', 'Considerate', 'Responsible', 'Informative', 'Reassuring', 'Positive'
                          ];
                          const negativeEmotions = ['Hesitant', 'Concerned', 'Frustrated', 'Aggressive','Anxious',"Desperate"];
                          const neutralEmotions = ['Suggestive', 'Explanatory', 'Practical', 'Neutral', 'Questioning'];
                          
                          // keyEmotions ç‚ºç¸½å’Œæ­£è² ç›¸çš„å­—è©
                          const keyEmotions = [...positiveEmotions, ...negativeEmotions, ...neutralEmotions];
                          
                          audioTimelineData.timeline.forEach(conversation => {
                            if (conversation.userAudio?.audioInfo && !processedAudioInfo.has(conversation.userAudio.audioInfo)) {
                              processedAudioInfo.add(conversation.userAudio.audioInfo);
                              const audioInfo = parseAudioInfo(conversation.userAudio.audioInfo);
                              if (audioInfo) {
                                audioInfo.emotions.forEach(emotion => {
                                  const emotions = emotion.emotion.split(/[,\s]+/).filter(e => e.trim() !== '');

                                  console.log(`emotions: ${emotions}`);  
                                  emotions.forEach(singleEmotion => {
                                    const trimmedEmotion = singleEmotion.trim();
                                    if (keyEmotions.includes(trimmedEmotion)) {
                                      chartEmotions[trimmedEmotion] = (chartEmotions[trimmedEmotion] || 0) + 1;
                                    } else {
                                      chartEmotions['Others'] = (chartEmotions['Others'] || 0) + 1;
                                    }
                                  });
                                });
                              }
                            }
                          });
                          
                          return Object.entries(chartEmotions).map(([emotion, count]) => ({
                            emotion,
                            count
                          }));
                        })()}
                        margin={{ top: 20, right: 30, left: 20, bottom: 5 }}
                      >
                        <CartesianGrid strokeDasharray="3 3" stroke="#2D5A67" />
                        <XAxis 
                          dataKey="emotion" 
                          tick={{ fill: '#ffffff', fontSize: 12 }}
                          angle={-45}
                          textAnchor="end"
                          height={80}
                        />
                        <YAxis 
                          tick={{ fill: '#ffffff', fontSize: 12 }}
                        />
                        <Tooltip 
                          contentStyle={{ 
                            backgroundColor: '#173944', 
                            border: '1px solid #2D5A67',
                            borderRadius: '8px',
                            color: '#ffffff'
                          }}
                          formatter={(value, name) => [value + ' æ¬¡', 'å‡ºç¾æ¬¡æ•¸']}
                          labelFormatter={(label) => `æƒ…ç·’: ${label}`}
                        />
                        <Bar 
                          dataKey="count" 
                          fill="#FFE066"
                          radius={[4, 4, 0, 0]}
                        />
                      </BarChart>
                    </ResponsiveContainer>
                  </div>
                </div>
              )}
            </div>


            {/* Radar Chart */}
            <div className="p-6 bg-[#173944] rounded-[20px] border border-[#2D5A67] shadow-[0_4px_20px_rgba(0,160,255,0.15)]">
              <h3 className="text-xl font-semibold text-white mb-6 flex items-center">
                <FaChartBar className="mr-2 text-[#FFE066]" />
                èªéŸ³è¡¨é”èƒ½åŠ›é›·é”åœ–
              </h3>
              <div className="h-96">
                <ResponsiveContainer width="100%" height="100%">
                  <RadarChart data={localAnalysis?.scores.map(score => ({
                    criterion: score.criterion,
                    score: score.score,
                    fullMark: 100
                  }))}>
                    <PolarGrid stroke="#2D5A67" />
                    <PolarAngleAxis 
                      dataKey="criterion" 
                      tick={{ 
                        fill: '#ffffff', 
                        fontSize: 12,
                        textAnchor: 'middle'
                      }}
                      className="text-white"
                    />
                    <PolarRadiusAxis
                      angle={90}
                      domain={[0, 100]}
                      tick={{ fill: '#ffffff', fontSize: 10 }}
                      tickCount={6}
                    />
                    <Radar
                      name="åˆ†æ•¸"
                      dataKey="score"
                      stroke="#FFE066"
                      fill="#FFE066"
                      fillOpacity={0.3}
                      strokeWidth={2}
                    />
                  </RadarChart>
                </ResponsiveContainer>
              </div>
            </div>


            {/* Audio Timeline Section */}
            {isAudioTimeline && renderAudioTimeline()}

            
          </div>
        </>
      )}
    </div>
  );
} 